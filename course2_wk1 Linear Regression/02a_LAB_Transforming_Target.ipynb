{"cells":[{"cell_type":"markdown","id":"03b67d7b-c5be-4125-826b-d2c96f03291f","metadata":{},"outputs":[],"source":["# Machine Learning Foundation\n","\n","## Section 2, Part a: Regression Intro: Transforming Target \n"]},{"cell_type":"markdown","id":"ec5faba2-7420-4290-b837-022bc998b276","metadata":{},"outputs":[],"source":["## Learning objectives\n","\n","By the end of this lesson, you will be able to:\n","\n","* Apply transformations to make target variable more normally distributed for Regression\n","* Apply inverse transformations to be able to use these in a Regression context\n"]},{"cell_type":"markdown","id":"58e23a29-bfeb-40b5-ac34-583405c3bf52","metadata":{},"outputs":[],"source":["\u003e Note:The lab is not using Boston Dataset as it has been deprecated by scikit due to ethical issues. More information on this is avaliable at https://scikit-learn.org/1.1/modules/generated/sklearn.datasets.load_boston.html. This lab uses a very similar dataset based on california housing.\n"]},{"cell_type":"code","id":"2c9fa9b9-8cb0-4b44-8516-b8a13bf8d53a","metadata":{},"outputs":[],"source":["!pip install -U scikit-learn"]},{"cell_type":"code","id":"a9eecee7-4f00-424e-a823-841eeb694d25","metadata":{},"outputs":[],"source":["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Surpress warnings:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn"]},{"cell_type":"markdown","id":"03931203-6d2d-41c6-974b-89a66cb708ab","metadata":{},"outputs":[],"source":["In the following cells we will load the data and define some useful plotting functions.\n"]},{"cell_type":"code","id":"d38ca3c2-40d3-46d6-8edf-97720d0d6d97","metadata":{},"outputs":[],"source":["np.random.seed(72018)\n\n\ndef to_2d(array):\n    return array.reshape(array.shape[0], -1)\n    \ndef plot_exponential_data():\n    data = np.exp(np.random.normal(size=1000))\n    plt.hist(data)\n    plt.show()\n    return data\n    \ndef plot_square_normal_data():\n    data = np.square(np.random.normal(loc=5, size=1000))\n    plt.hist(data)\n    plt.show()\n    return data"]},{"cell_type":"markdown","id":"3adf728c-cd4e-4708-8085-aa3e072dda91","metadata":{},"outputs":[],"source":["### Loading the California Housing Data\n"]},{"cell_type":"code","id":"2bc643f8-21fd-48ca-a1c4-c7c10b28bfa7","metadata":{},"outputs":[],"source":["import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import fetch_california_housing\n\nhousing = fetch_california_housing(download_if_missing=True)\n\ndata = np.c_[housing.data, housing.target]\ncolumns = np.append(housing.feature_names, [\"MedVal\"])\nhousing_df = pd.DataFrame(data, columns=columns)"]},{"cell_type":"code","id":"309778c9-5883-488a-944b-4f07763ea20b","metadata":{},"outputs":[],"source":["housing_df.head(15)"]},{"cell_type":"markdown","id":"803f98c0-75a7-45d2-815d-d327130cff00","metadata":{},"outputs":[],"source":["### Determining Normality\n"]},{"cell_type":"markdown","id":"cac827de-45d3-4ddb-bc6d-c83d0db5c9d5","metadata":{},"outputs":[],"source":["Making our target variable normally distributed often will lead to better results\n","\n","If our target is not normally distributed, we can apply a transformation to it and then fit our regression to predict the transformed values.\n","\n","How can we tell if our target is normally distributed? There are two ways:\n","\n","* Using a Visual approach\n","* Using a Statistical Test\n"]},{"cell_type":"markdown","id":"a08be94d-7c90-45b8-8c17-3e894877d39b","metadata":{},"outputs":[],"source":["#### Using a Visual approach\n"]},{"cell_type":"markdown","id":"a6664931-94e2-4244-acb9-74bb7763b4d6","metadata":{},"outputs":[],"source":["#### Plotting a histogram:\n"]},{"cell_type":"code","id":"2c3d5ae3-19a2-45f9-84a3-d0bdff85f3ff","metadata":{},"outputs":[],"source":["housing_df.MedVal.hist();"]},{"cell_type":"markdown","id":"23f47748-fed6-479f-b7ad-67311dfa1a4f","metadata":{},"outputs":[],"source":["The histogram does not look normal due to its right tail.\n"]},{"cell_type":"markdown","id":"328a272b-b55b-4a16-b59b-cf508aae48ca","metadata":{},"outputs":[],"source":["#### Using a Statistical Test\n"]},{"cell_type":"markdown","id":"b4a34365-8fea-40db-941a-7e4236bac46d","metadata":{},"outputs":[],"source":["Without getting into Bayesian vs. frequentist debates, for the purposes of this lesson, the following will suffice:\n","\n","* This is a statistical test that tests whether a distribution is normally distributed or not. It isn't perfect, but suffice it to say: \n","    * This test outputs a **p-value**. The _higher_ this p-value is the _closer_ the distribution is to normal.\n","    * Frequentist statisticians would say that you accept that the distribution is normal (more specifically: fail to reject the null hypothesis that it is normal) if p \u003e 0.05.\n"]},{"cell_type":"code","id":"ece186ad-adee-40cc-8dff-8768c1bf8693","metadata":{},"outputs":[],"source":["from scipy.stats.mstats import normaltest # D'Agostino K^2 Test"]},{"cell_type":"code","id":"cc399996-6b7a-47b7-8d02-617222e1db15","metadata":{},"outputs":[],"source":["normaltest(housing_df.MedVal.values)"]},{"cell_type":"markdown","id":"57742009-88cb-48c3-80c7-86a955e2a6de","metadata":{},"outputs":[],"source":["p-value is _extremely_ low. Our **y** variable which we have been dealing with this whole time was not normally distributed!\n"]},{"cell_type":"markdown","id":"1bdb4005-6cfd-4f08-96a9-542d04dd1306","metadata":{},"outputs":[],"source":["### Apply transformations to make target variable more normally distributed for Regression\n"]},{"cell_type":"markdown","id":"ba228fae-a7cd-4ea3-bf54-1a25ec383235","metadata":{},"outputs":[],"source":["Linear Regression assumes a normally distributed residuals which can be aided by transforming **y** variable which is the target variable. Let's try some common transformations to try and get **y** to be normally distributed: \n","\n","* Log Transformation\n","* Square root Transformation\n","* Box cox Transformation\n"]},{"cell_type":"markdown","id":"bd151839-a228-44f1-bf6c-d68a59842f3d","metadata":{},"outputs":[],"source":["### Log Transformation\n"]},{"cell_type":"markdown","id":"d05be4ff-172e-4286-b60e-7d82cecb7cd1","metadata":{},"outputs":[],"source":["The log transformation can transform data that is significantly skewed right to be more normally distributed:\n"]},{"cell_type":"code","id":"de16985e-cf3c-4897-9d2b-b7ce85165f8d","metadata":{},"outputs":[],"source":["data = plot_exponential_data()"]},{"cell_type":"code","id":"c03fb5d1-bbb4-41bb-9e0b-525a43cdf15d","metadata":{},"outputs":[],"source":["plt.hist(np.log(data));"]},{"cell_type":"markdown","id":"53c9f4c6-9510-47a4-8600-323638f6c53f","metadata":{},"outputs":[],"source":["**Apply transformation to California Housing data:**\n"]},{"cell_type":"code","id":"d84a803b-10f4-4d1d-a326-47c1b7171a2a","metadata":{},"outputs":[],"source":["log_medv = np.log(housing_df.MedVal)"]},{"cell_type":"code","id":"95ee19ba-dba0-47b1-93b4-d2143b130c2b","metadata":{},"outputs":[],"source":["log_medv.hist();"]},{"cell_type":"code","id":"0a593f65-06c9-4934-95ba-45f8d8bb31ee","metadata":{},"outputs":[],"source":["normaltest(log_medv)"]},{"cell_type":"markdown","id":"fd9b4ccd-0478-4393-9b7c-fcc9e855b4cc","metadata":{},"outputs":[],"source":["Conclusion: The output is closer to normal distribution, but still not completely normal.\n"]},{"cell_type":"markdown","id":"a4d50fce-1950-4153-b7a7-599b2e6d56d7","metadata":{},"outputs":[],"source":["### Square root Transformation\n","\n","The square root transformation is another transformation that can transform non-normally distributed data into normally distributed data:\n"]},{"cell_type":"code","id":"ace960a3-13ab-4d2e-b037-e432b1c5d9b0","metadata":{},"outputs":[],"source":["data = plot_square_normal_data()"]},{"cell_type":"markdown","id":"f006034b-ba8b-4571-8887-6f11d78fb874","metadata":{},"outputs":[],"source":["You may notice that the output still exhibits a slight right skew.\n"]},{"cell_type":"code","id":"51a7b895-5a60-4c4e-9419-21c80f566dbf","metadata":{},"outputs":[],"source":["plt.hist(np.sqrt(data));"]},{"cell_type":"markdown","id":"4d67cf38-91ce-4dc4-8bfc-ed3f328afc8f","metadata":{},"outputs":[],"source":["#### Exercise\n"]},{"cell_type":"markdown","id":"86b5a1cc-7b57-4c44-b094-8400cea14240","metadata":{},"outputs":[],"source":["Apply the square root transformation to the California Housing data target and test whether the result is normally distributed.\n"]},{"cell_type":"code","id":"a171cc38-8545-4664-aadd-12d5c19b0954","metadata":{},"outputs":[],"source":["## Enter your code here\n"]},{"cell_type":"markdown","id":"92b913f8-b710-4215-905b-db671d25408e","metadata":{},"outputs":[],"source":["Click \u003cb\u003ehere\u003c/b\u003e for the solution.\n","\n","\u003c!-- The answer is below:\n","\n","sqrt_medv = np.sqrt(housing_df.MedVal)\n","plt.hist(sqrt_medv)\n","--\u003e\n"]},{"cell_type":"code","id":"d8545c37-a326-4d28-93f9-e3cf4c5bcd3d","metadata":{},"outputs":[],"source":["normaltest(sqrt_medv)"]},{"cell_type":"markdown","id":"088a26a6-60da-4568-9d4f-97b4b01a39a6","metadata":{},"outputs":[],"source":["### Box cox Transformation\n"]},{"cell_type":"markdown","id":"3dcc9ce7-3ecf-4348-8229-cb226adc23cc","metadata":{},"outputs":[],"source":["The box cox transformation is a parametrized transformation that tries to get distributions \"as close to a normal distribution as possible\".\n","\n","It is defined as:\n","\n","$$ \\text{boxcox}(y_i) = \\frac{y_i^{\\lambda} - 1}{\\lambda} $$\n","\n","You can think of as a generalization of the square root function: the square root function uses the exponent of 0.5, but box cox lets its exponent vary so it can find the best one.\n"]},{"cell_type":"code","id":"2d432571-34aa-4581-b632-3dc858e3500b","metadata":{},"outputs":[],"source":["from scipy.stats import boxcox"]},{"cell_type":"code","id":"3a47903e-e2dd-4f9d-88a2-f67dd0d2c63a","metadata":{},"outputs":[],"source":["bc_result = boxcox(housing_df.MedVal)\nboxcox_medv = bc_result[0]\nlam = bc_result[1]"]},{"cell_type":"code","id":"c86d4854-71eb-4dad-9b5a-0270221527ed","metadata":{},"outputs":[],"source":["lam"]},{"cell_type":"code","id":"38ce45e5-e2b9-4bb2-9fbf-c808cf5b892c","metadata":{},"outputs":[],"source":["housing_df['MedVal'].hist();"]},{"cell_type":"code","id":"a13ae6bc-945b-43cf-9422-7bccd6e46e41","metadata":{},"outputs":[],"source":["plt.hist(boxcox_medv);"]},{"cell_type":"code","id":"9623b067-20c1-4590-81a0-15c96e957bdc","metadata":{},"outputs":[],"source":["normaltest(boxcox_medv)"]},{"cell_type":"markdown","id":"1835a1cb-bacf-4f0d-b6d3-2011241ffbb1","metadata":{},"outputs":[],"source":["We find that the box cox results in a graph which is significantly more normally distributed (according to p value) than the other two distributions.This can be even above 0.05.\n","\n","Now that we have a normally distributed y-variable, let's test Regression using this transformed target variables.\n"]},{"cell_type":"markdown","id":"9f084256-7287-443f-9c7f-0574bceb1468","metadata":{},"outputs":[],"source":["### Testing regression:\n"]},{"cell_type":"code","id":"54eb5460-5856-4144-bee2-561e78763a08","metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import (StandardScaler, \n                                   PolynomialFeatures)"]},{"cell_type":"code","id":"33401c8c-7353-4feb-a32d-da53a6f1bc5b","metadata":{},"outputs":[],"source":["lr = LinearRegression()"]},{"cell_type":"markdown","id":"cff590a1-d528-4354-a5dc-510737a207bd","metadata":{},"outputs":[],"source":["**Load the dataframe `housing_df`:**\n"]},{"cell_type":"code","id":"158f2eb2-1226-454e-b9fd-1e75b53ada4d","metadata":{},"outputs":[],"source":["data = np.c_[housing.data, housing.target]\ncolumns = np.append(housing.feature_names, [\"MedVal\"])\nhousing_df = pd.DataFrame(data, columns=columns)"]},{"cell_type":"markdown","id":"d64ee2ae-5254-4500-995d-8533781244e7","metadata":{},"outputs":[],"source":["**Define and load the predictor (X) and Target(y) variables **\n"]},{"cell_type":"code","id":"ab1a0c3a-dd55-40fc-b8aa-db87cf3b63cf","metadata":{},"outputs":[],"source":["y_col = \"MedVal\"\n\nX = housing_df.drop(y_col, axis=1)\ny = housing_df[y_col]"]},{"cell_type":"markdown","id":"8de67112-8d7c-4dcd-a582-b9a681dc8a11","metadata":{},"outputs":[],"source":["**Create Polynomial Features**\n"]},{"cell_type":"code","id":"859dc8e1-d5ab-4bc6-9f2b-55552b2ba0af","metadata":{},"outputs":[],"source":["pf = PolynomialFeatures(degree=2, include_bias=False)\nX_pf = pf.fit_transform(X)"]},{"cell_type":"markdown","id":"d7dde5db-9416-42b7-bf4f-0f849483c276","metadata":{},"outputs":[],"source":["**Split the data into Training and Test Sets**   \n","\n","The split ratio here is 0.7 and 0.3 which means we will assign **70%** data for training and **30%** data for testing\n"]},{"cell_type":"code","id":"97caeecc-0ae9-4a33-bd93-1fd214119f12","metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X_pf, y, test_size=0.3, \n                                                    random_state=72018)"]},{"cell_type":"markdown","id":"cd78df06-21c5-447e-a77d-212bb594cd59","metadata":{},"outputs":[],"source":["**Normalize the training data using `StandardScaler` on `X_train`. Use fit_transform() function**\n"]},{"cell_type":"code","id":"42693f1f-ad60-4917-90e7-51dab34d1f0c","metadata":{},"outputs":[],"source":["s = StandardScaler()\nX_train_s = s.fit_transform(X_train)"]},{"cell_type":"markdown","id":"6aa4e890-e636-4be6-ab8e-676ea98b2b06","metadata":{},"outputs":[],"source":["**Discuss: what transformation do we need to apply next?**\n","\n","Apply the appropriate transformation.\n"]},{"cell_type":"code","id":"7b017d63-bf02-48e0-a6fc-dfa5bcb31918","metadata":{},"outputs":[],"source":["# Enter your code here"]},{"cell_type":"markdown","id":"fd8e1156-1f26-4222-813a-a7bea988fc86","metadata":{},"outputs":[],"source":["Click \u003cb\u003ehere\u003c/b\u003e for the solution.\n","\n","\u003c!-- The answer is below:\n","\n","bc_result2 = boxcox(y_train)\n","y_train_bc = bc_result2[0]\n","lam2 = bc_result2[1]\n","--\u003e\n"]},{"cell_type":"markdown","id":"d6927c4d-1926-4a7e-a5fd-5b6e0c889a0f","metadata":{},"outputs":[],"source":["As before, we'll now:\n","\n","1. Fit regression\n","1. Transform testing data\n","1. Predict on testing data\n"]},{"cell_type":"code","id":"a3c40afe-1ade-4172-9fc6-04d823c4f177","metadata":{},"outputs":[],"source":["y_train_bc.shape"]},{"cell_type":"code","id":"d66bff56-824c-43e6-807c-f05e19094828","metadata":{},"outputs":[],"source":["lr.fit(X_train_s, y_train_bc)\nX_test_s = s.transform(X_test)\ny_pred_bc = lr.predict(X_test_s)"]},{"cell_type":"markdown","id":"9339335c-ce38-4f02-b18a-f3bc034d085d","metadata":{},"outputs":[],"source":["### Discussion\n","\n","* Are we done?\n","* What did we predict?\n","* How would you interpret these predictions?\n"]},{"cell_type":"markdown","id":"ba8e1e1c-231e-45ef-8493-25f8b98c7c5e","metadata":{},"outputs":[],"source":["#### Apply inverse transformations to be able to use these in a Regression context\n"]},{"cell_type":"markdown","id":"72005c68-c1ca-4ec4-be43-6bfdb1434193","metadata":{},"outputs":[],"source":["Every transformation has an inverse transformation. The inverse transformation of $f(x) = \\sqrt{x}$ is $f^{-1}(x) = x^2$, for example. Box cox has an inverse transformation as well: notice that we have to pass in the lambda value that we found from before:\n"]},{"cell_type":"code","id":"b24e25cd-dae2-4390-bc72-0c653c757ec6","metadata":{},"outputs":[],"source":["from scipy.special import inv_boxcox"]},{"cell_type":"code","id":"372d4c5c-ec20-4d61-8e1e-8271d7b1c2f5","metadata":{},"outputs":[],"source":["# code from above\nbc_result = boxcox(housing_df.MedVal)\nboxcox_medv = bc_result[0]\nlam = bc_result[1]"]},{"cell_type":"code","id":"c77833c0-1802-41ad-900a-3b9282ec8cf2","metadata":{},"outputs":[],"source":["inv_boxcox(boxcox_medv, lam)[:10]"]},{"cell_type":"code","id":"03fb856c-9976-44ea-af4f-6387ef654438","metadata":{},"outputs":[],"source":["housing_df['MedVal'].values[:10]"]},{"cell_type":"markdown","id":"1d228070-2ba8-41a8-bf89-36f936b49fb8","metadata":{},"outputs":[],"source":["Exactly the same, as we would hope!\n"]},{"cell_type":"markdown","id":"204a0cdb-4c3f-41ae-a46c-130a66b68fe8","metadata":{},"outputs":[],"source":["### Exercise:\n","\n","1. Apply the appropriate inverse transformation to `y_pred_bc`.\n","2. Calculate the $R^2$ using the result of this inverse transformation and `y_test`.  \n","\n","**Hint:** Use the **inv_boxcox()** function to get the transformed predicted values\n"]},{"cell_type":"code","id":"b8287d73-f7c6-4430-9b07-1249a733f7b0","metadata":{},"outputs":[],"source":["#Enter your code here"]},{"cell_type":"markdown","id":"454face9-74c7-4f92-bfaa-08f84984c6e4","metadata":{},"outputs":[],"source":["Click \u003cb\u003ehere\u003c/b\u003e for the solution.\n","\n","\u003c!-- The answer is below:\n","\n","y_pred_tran = inv_boxcox(y_pred_bc,lam2)\n","r2_score(y_pred_tran,y_test)\n","--\u003e\n"]},{"cell_type":"markdown","id":"f7c7bff2-8600-4495-b88f-e02c30ee644c","metadata":{},"outputs":[],"source":["## Practice Exercise: \n","\n","### Determine the R^2 of a LinearRegression without the box cox transformation.\n"]},{"cell_type":"code","id":"b2418796-d5dc-4ee7-ab72-38ce875a2d39","metadata":{},"outputs":[],"source":["# Enter your code here"]},{"cell_type":"markdown","id":"9377ba0f-3bb5-4788-b0be-caac64991ecc","metadata":{},"outputs":[],"source":["Click \u003cb\u003ehere\u003c/b\u003e for the solution.\n","\n","\u003c!-- The answer is below:\n","\n","lr = LinearRegression()\n","lr.fit(X_train_s,y_train)\n","lr_pred = lr.predict(X_test_s)\n","r2_score(lr_pred,y_test)\n","--\u003e\n"]},{"cell_type":"markdown","id":"a7b532ed-563c-456d-b8a6-4c41b170e989","metadata":{},"outputs":[],"source":["---\n","### Machine Learning Foundation (C) 2023 IBM Corporation\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}